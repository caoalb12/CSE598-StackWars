{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V5E1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMMShC7EmC35",
        "outputId": "365c5c89-1e83-45fe-e24c-c32cd33058cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jax/_src/cloud_tpu_init.py:86: UserWarning: Transparent hugepages are not enabled. TPU runtime startup and shutdown time should be significantly improved on TPU v5e and newer. If not already set, you may need to enable transparent hugepages in your VM image (sudo sh -c \"echo always > /sys/kernel/mm/transparent_hugepage/enabled\")\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "from jax import random"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "master_key = random.PRNGKey(0)\n",
        "num_runs = 10"
      ],
      "metadata": {
        "id": "GlePQgD3vrMu"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gemm(a, b):\n",
        "  return jnp.matmul(a, b)"
      ],
      "metadata": {
        "id": "ZoX04oMzmbA_"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ffn(x, w1, b1, w2, b2):\n",
        "  \"\"\"\n",
        "  Feed Forward Network:\n",
        "    Input: (128, 64, 256)\n",
        "    w1=(256,1024), b1=(1024)\n",
        "    w2=(1024,256), b2=(256)\n",
        "  \"\"\"\n",
        "  h = jnp.matmul(x, w1) + b1\n",
        "  h = jax.nn.relu(h)\n",
        "  return jnp.matmul(h, w2) + b2"
      ],
      "metadata": {
        "id": "DhpeErb_pGkw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mha(x, w_q, w_k, w_v, w_o, num_heads=16):\n",
        "    \"\"\"\n",
        "    Multi-Head Self-Attention (MHA) benchmark.\n",
        "\n",
        "    Args:\n",
        "        x: Input tensor of shape (batch, seq_len, embed_dim)\n",
        "        w_q, w_k, w_v: Projection weights for Q, K, V (embed_dim, embed_dim)\n",
        "        w_o: Output projection weight (embed_dim, embed_dim)\n",
        "        num_heads: Number of attention heads (default 16)\n",
        "    Returns:\n",
        "        Tensor of shape (batch, seq_len, embed_dim)\n",
        "    \"\"\"\n",
        "\n",
        "    batch, seq_len, embed_dim = x.shape\n",
        "    head_dim = embed_dim // num_heads\n",
        "\n",
        "    # Get query, key, and value vectors for each token.\n",
        "    q = jnp.dot(x, w_q)\n",
        "    k = jnp.dot(x, w_k)\n",
        "    v = jnp.dot(x, w_v)\n",
        "\n",
        "    # Reshape to (batch, num_heads, seq_len, head_dim).\n",
        "    def reshape_heads(t):\n",
        "        return t.reshape(batch, seq_len, num_heads, head_dim).transpose(0, 2, 1, 3)\n",
        "\n",
        "    q, k, v = map(reshape_heads, (q, k, v))\n",
        "\n",
        "    # Scaled dot product attention per head.\n",
        "    d_k = head_dim\n",
        "    scores = jnp.matmul(q, jnp.swapaxes(k, -2, -1)) / jnp.sqrt(d_k)   # (B, H, S, S)\n",
        "    attn_weights = jax.nn.softmax(scores, axis=-1)\n",
        "    attn_output = jnp.matmul(attn_weights, v)                         # (B, H, S, d_k)\n",
        "\n",
        "    # Recombine heads.\n",
        "    attn_output = attn_output.transpose(0, 2, 1, 3).reshape(batch, seq_len, embed_dim)\n",
        "\n",
        "    # Project back input embedding dimension.\n",
        "    output = jnp.dot(attn_output, w_o)\n",
        "    return output"
      ],
      "metadata": {
        "id": "AR7TPv4QoRAZ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_layer(x, w):\n",
        "  \"\"\"\n",
        "    N = batch size\n",
        "    C = input channels\n",
        "    H = input height\n",
        "    W = input width\n",
        "\n",
        "    O = output channels (number of filters)\n",
        "    I = input channels (like RGB)\n",
        "    H = kernel height\n",
        "    W = kernel width\n",
        "\n",
        "    x = input tensor of shape (N, I, H, W) (input height and width)\n",
        "    w = weight tensor of shape (O, I, H, W) (kernel height and width)\n",
        "  \"\"\"\n",
        "  return jax.lax.conv_general_dilated(\n",
        "      lhs=x, rhs=w,\n",
        "      window_strides=(1, 1),\n",
        "      padding='SAME',\n",
        "      dimension_numbers=('NCHW', 'OIHW', 'NCHW')\n",
        "  )\n"
      ],
      "metadata": {
        "id": "GH_Z8jCHtKzs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install graphviz\n",
        "\n",
        "from pathlib import Path\n",
        "import re\n",
        "from graphviz import Digraph\n",
        "\n",
        "def visualize_mlir(mlir_path, func_name, graph_path):\n",
        "  with open(mlir_path) as f:\n",
        "      text = f.read()\n",
        "\n",
        "  # matches like: %2 = stablehlo.dot_general %0, %1, ...\n",
        "  pattern = re.compile(r\"(%\\w+)\\s*=\\s*([\\w\\.]+)\\s+(.*)\")\n",
        "  ops = []\n",
        "  for line in text.splitlines():\n",
        "      line = line.strip()\n",
        "      m = pattern.match(line)\n",
        "      if not m:\n",
        "          continue\n",
        "      out, op, rest = m.groups()\n",
        "      # Extract inputs like %0, %1\n",
        "      inputs = re.findall(r\"%\\w+\", rest)\n",
        "      ops.append((out, op, inputs))\n",
        "\n",
        "  g = Digraph(\"StableHLO\", format=\"png\")\n",
        "  g.attr(rankdir=\"LR\")\n",
        "\n",
        "  for out, op, inputs in ops:\n",
        "      g.node(out, f\"{out}\\n{op}\")\n",
        "\n",
        "      for inp in inputs:\n",
        "          g.edge(inp, out)\n",
        "\n",
        "  for arg in re.findall(r\"(%arg\\d+):\", text):\n",
        "      g.node(arg, f\"{arg}\\ninput\", shape=\"box\")\n",
        "\n",
        "  ret = re.search(r\"return\\s+(.*)\\s*:\", text)\n",
        "  if ret:\n",
        "      outs = re.findall(r\"%\\w+\", ret.group(1))\n",
        "      for o in outs:\n",
        "          g.edge(o, \"return\")\n",
        "      g.node(\"return\", \"return\", shape=\"box\")\n",
        "\n",
        "  g.render(graph_path, view=True, cleanup=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewnn2vlh87wM",
        "outputId": "89528222-97f7-4d3e-9645-56e2b6282da6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting graphviz\n",
            "  Downloading graphviz-0.21-py3-none-any.whl.metadata (12 kB)\n",
            "Downloading graphviz-0.21-py3-none-any.whl (47 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/47.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: graphviz\n",
            "Successfully installed graphviz-0.21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time, math\n",
        "import jax, os\n",
        "import jax.numpy as jnp\n",
        "import shutil, glob, gzip\n",
        "import numpy as np\n",
        "\n",
        "import json\n",
        "\n",
        "import gc\n",
        "\n",
        "gc.collect()\n",
        "jax.clear_caches()\n",
        "\n",
        "def extract_tpu_ops(trace_json):\n",
        "    fields = [\"name\",  \"timestamp_ns\", \"duration_ns\",\n",
        "              \"bytes_accessed\", \"raw_bytes_accessed\",\n",
        "              \"device_duration_ps\", \"device_offset_ps\",\n",
        "              \"hlo_category\", \"model_flops\", \"long_name\"\n",
        "              \"shape_with_layout\", \"tf_op\"]\n",
        "\n",
        "    tpu_ops = []\n",
        "\n",
        "    for event in trace_json.get(\"traceEvents\", []):\n",
        "        if event.get(\"ph\") != \"X\":\n",
        "            continue\n",
        "\n",
        "        args = event.get(\"args\", {})\n",
        "        if \"device_duration_ps\" not in args and \"hlo_category\" not in args:\n",
        "            continue\n",
        "\n",
        "        op = {\n",
        "            \"name\": event.get(\"name\", \"\"),\n",
        "            \"timestamp_ns\": event.get(\"ts\"),\n",
        "            \"duration_ns\": event.get(\"dur\"),\n",
        "        }\n",
        "\n",
        "        # Add all optional fields from args\n",
        "        for field in [\"bytes_accessed\", \"raw_bytes_accessed\", \"device_duration_ps\",\n",
        "                      \"device_offset_ps\", \"hlo_category\", \"model_flops\",\n",
        "                      \"shape_with_layout\", \"long_name\", \"tf_op\"]:\n",
        "            op[field] = args.get(field)\n",
        "\n",
        "        tpu_ops.append(op)\n",
        "\n",
        "    lines = []\n",
        "    for i, op in enumerate(tpu_ops, 1):\n",
        "        lines.append(f\"--- TPU Op {i} ---\")\n",
        "        for k, v in op.items():\n",
        "            lines.append(f\"{k:20}: {v}\")\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "# Return function call time in ms.\n",
        "def profile_func_call(func_name, compiled_func, get_trace, *args):\n",
        "    logs_dir = f\"logs/{func_name}\"\n",
        "\n",
        "    # First call will include compile time.\n",
        "    t_s = time.perf_counter()\n",
        "    compiled_func(*args).block_until_ready()\n",
        "    t_e = time.perf_counter()\n",
        "\n",
        "    # Generate trace.\n",
        "    if get_trace:\n",
        "      jax.profiler.start_trace(logs_dir)\n",
        "      compiled_func(*args).block_until_ready()\n",
        "      jax.profiler.stop_trace()\n",
        "\n",
        "    return (t_e - t_s) * 1000\n",
        "\n",
        "def write_trace_summary(root_profile_dir):\n",
        "    trace_files = glob.glob(os.path.join(root_profile_dir, \"**\", \"*.json.gz\"), recursive=True)\n",
        "\n",
        "    with gzip.open(trace_files[0], \"rt\", encoding=\"utf-8\") as f:\n",
        "        trace_json = json.load(f)\n",
        "\n",
        "    summary_text = extract_tpu_ops(trace_json)\n",
        "\n",
        "    summary_path = os.path.join(root_profile_dir, \"summary.txt\")\n",
        "    with open(summary_path, \"w\") as f:\n",
        "        f.write(summary_text)\n",
        "\n",
        "def profile_jax_function(func_name, func, num_runs, *args):\n",
        "    print(f\"Profiling {func_name}.\\n\")\n",
        "\n",
        "    dir_to_remove = f\"logs/{func_name}\"\n",
        "    if os.path.exists(dir_to_remove):\n",
        "      shutil.rmtree(dir_to_remove)\n",
        "\n",
        "    compiled_func = jax.jit(func)\n",
        "\n",
        "    first_call_time = profile_func_call(func_name, compiled_func, True, *args)\n",
        "    print(f\"Run 0: {first_call_time:.3f} ms.\")\n",
        "\n",
        "    all_times = []\n",
        "    for i in range(num_runs):\n",
        "        run_time = profile_func_call(func_name, compiled_func, False, *args)\n",
        "        all_times.append(run_time)\n",
        "        print(f\"Run {i+1}: {run_time:.3f} ms\")\n",
        "\n",
        "    avg_time = np.mean(all_times)\n",
        "    std_time = np.std(all_times)\n",
        "    print(f\"\\nAverage over {num_runs} runs: {avg_time:.3f} ms ± {std_time:.3f} ms.\")\n",
        "\n",
        "    root_profile_dir = f\"{dir_to_remove}/plugins/profile\"\n",
        "    write_trace_summary(root_profile_dir)\n",
        "\n",
        "    stablehlo_ir = compiled_func.lower(*args).compiler_ir(\"stablehlo\")\n",
        "    mlir_path = f\"{root_profile_dir}/stablehlo.txt\"\n",
        "    graph_path = f\"{root_profile_dir}/stablehlo\"\n",
        "\n",
        "    with open(mlir_path, \"w\") as f:\n",
        "        f.write(str(stablehlo_ir))\n",
        "\n",
        "    visualize_mlir(mlir_path, func_name, graph_path)"
      ],
      "metadata": {
        "id": "xm1c2u4ov_WK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keys = random.split(master_key, 2)\n",
        "\n",
        "A = random.normal(keys[0], (128, 256))\n",
        "B = random.normal(keys[1], (256, 1024))\n",
        "\n",
        "profile_jax_function(\"GEMM\", gemm, num_runs, A, B)\n",
        "\n",
        "# Trace had two steps: copy-done and fusion.\n",
        "# Copy seemed to only moves tensor B (GPT says it's rearranging the tensor for more efficient computation).\n",
        "  # %copy-done = f32[256,1024]{1,0:T(8,128)S(1)} copy-done((f32[256,1024]{1,0:T(8,128)S(1)}, f32[256,1024]{1,0:T(8,128)}, u32[]{:S(2)}) %copy-start)\n",
        "# The fusion read all of A and B and wrote the output.\n",
        "  # %fusion = f32[128,1024]{1,0:T(8,128)} fusion(f32[128,256]{1,0:T(8,128)} %Arg_0.1, f32[256,1024]{1,0:T(8,128)S(1)} %copy-done), kind=kOutput, calls=%fused_computation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cddHpZdPwmOO",
        "outputId": "4487ed82-90bf-4afe-fcf6-161b4fda2d7f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Profiling GEMM.\n",
            "\n",
            "Run 0: 55.935 ms.\n",
            "Run 1: 0.387 ms\n",
            "Run 2: 0.246 ms\n",
            "Run 3: 0.231 ms\n",
            "Run 4: 0.202 ms\n",
            "Run 5: 0.208 ms\n",
            "Run 6: 0.193 ms\n",
            "Run 7: 0.180 ms\n",
            "Run 8: 0.188 ms\n",
            "Run 9: 0.188 ms\n",
            "Run 10: 0.188 ms\n",
            "\n",
            "Average over 10 runs: 0.221 ms ± 0.059 ms.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys = random.split(master_key, 5)\n",
        "\n",
        "x = random.normal(keys[0], (128, 64, 256))\n",
        "w1 = random.normal(keys[1], (256, 1024))\n",
        "b1 = random.normal(keys[2], (1024,))\n",
        "w2 = random.normal(keys[3], (1024, 256))\n",
        "b2 = random.normal(keys[4], (256,))\n",
        "\n",
        "profile_jax_function(\"FFN\", ffn, num_runs, x, w1, b1, w2, b2)\n",
        "\n",
        "# First matrix multiplication is broken up into fusion and copy.1\n",
        "  # %copy-done = f32[256,1024]{1,0:T(8,128)S(1)} copy-done((f32[256,1024]{1,0:T(8,128)S(1)}, f32[256,1024]{1,0:T(8,128)}, u32[]{:S(2)}) %copy-start)\n",
        "  # %fusion = f32[128,64,1024]{2,0,1:T(8,128)S(1)} fusion(f32[128,64,256]{2,1,0:T(8,128)} %Arg_0.1, f32[256,1024,1]{1,0,2:T(8,128)S(1)} %bitcast.8), kind=kOutput, calls=%fused_computation\n",
        "  # %copy.1 = f32[128,64,1024]{2,1,0:T(8,128)} copy(f32[128,64,1024]{2,0,1:T(8,128)S(1)} %fusion)\n",
        "# We add the first bias.\n",
        "  # %broadcast_add_fusion = f32[128,64,1024]{2,1,0:T(8,128)} fusion(f32[128,64,1024]{2,1,0:T(8,128)} %Arg_0.1, f32[1024]{0:T(1024)} %Arg_1.2), kind=kLoop, calls=%fused_computation\n",
        "# Some stuff happens on the CPU in between.\n",
        "  # %broadcast_maximum_fusion = f32[128,64,1024]{2,1,0:T(8,128)} fusion(f32[128,64,1024]{2,1,0:T(8,128)} %Arg_0.1), kind=kLoop, calls=%fused_computation\n",
        "# Then the second matmul.\n",
        "  # %fusion.3 = f32[128,64,256]{2,1,0:T(8,128)} fusion(f32[128,64,1024]{2,1,0:T(8,128)S(1)} %copy-done, f32[1024,256,1]{1,0,2:T(8,128)} %bitcast.9), kind=kOutput, calls=%fused_computation.2\n",
        "# Then the second bias is added.\n",
        "  # %broadcast_add_fusion = f32[128,64,256]{2,1,0:T(8,128)} fusion(f32[128,64,256]{2,1,0:T(8,128)} %Arg_0.1, f32[256]{0:T(256)} %Arg_1.2), kind=kLoop, calls=%fused_computation\n",
        "\n",
        "# Maybe missing some details."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dVPoS5swqk-",
        "outputId": "28134225-ecd8-445c-e2fe-e0f91e6bb906"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Profiling FFN.\n",
            "\n",
            "Run 0: 565.346 ms.\n",
            "Run 1: 0.345 ms\n",
            "Run 2: 0.273 ms\n",
            "Run 3: 0.243 ms\n",
            "Run 4: 0.234 ms\n",
            "Run 5: 0.200 ms\n",
            "Run 6: 0.210 ms\n",
            "Run 7: 0.196 ms\n",
            "Run 8: 0.197 ms\n",
            "Run 9: 0.199 ms\n",
            "Run 10: 0.211 ms\n",
            "\n",
            "Average over 10 runs: 0.231 ms ± 0.045 ms.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keys = random.split(master_key, 5)\n",
        "\n",
        "batch, seq, embed, heads = 128, 64, 256, 16\n",
        "\n",
        "x = random.normal(keys[0], (batch, seq, embed))\n",
        "w_q = random.normal(keys[1], (embed, embed))\n",
        "w_k = random.normal(keys[2], (embed, embed))\n",
        "w_v = random.normal(keys[3], (embed, embed))\n",
        "w_o = random.normal(keys[4], (embed, embed))\n",
        "\n",
        "profile_jax_function(\"MHA\", mha, num_runs, x, w_q, w_k, w_v, w_o)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZq1kWmYwqZY",
        "outputId": "97fd73c8-edf1-42ce-da8b-b8c6db56601d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Profiling MHA.\n",
            "\n",
            "Run 0: 1015.022 ms.\n",
            "Run 1: 0.503 ms\n",
            "Run 2: 0.442 ms\n",
            "Run 3: 0.428 ms\n",
            "Run 4: 0.400 ms\n",
            "Run 5: 0.407 ms\n",
            "Run 6: 0.411 ms\n",
            "Run 7: 0.417 ms\n",
            "Run 8: 0.404 ms\n",
            "Run 9: 0.391 ms\n",
            "Run 10: 0.397 ms\n",
            "\n",
            "Average over 10 runs: 0.420 ms ± 0.031 ms.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# using built-in JAX convolution (probably why it's faster)\n",
        "\n",
        "keys = random.split(master_key, 2)\n",
        "\n",
        "batch, in_channels, input_height, input_width = 128, 3, 12, 12\n",
        "out_channels, kernel_height, kernel_width = 3, 3, 3\n",
        "\n",
        "# padding and stride are 1 (implicit in the function)\n",
        "\n",
        "x = random.normal(keys[0], (batch, in_channels, input_height, input_width))   # NCHW\n",
        "w = random.normal(keys[1], (out_channels, in_channels, kernel_height, kernel_width))       # OIHW\n",
        "\n",
        "profile_jax_function(\"Conv\", conv_layer, num_runs, x, w)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48oP3lAawqNL",
        "outputId": "1039868f-61ff-4dbc-a0ff-8ae39f59438d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Profiling Conv.\n",
            "\n",
            "Run 0: 128.949 ms.\n",
            "Run 1: 0.322 ms\n",
            "Run 2: 0.244 ms\n",
            "Run 3: 0.188 ms\n",
            "Run 4: 0.171 ms\n",
            "Run 5: 0.158 ms\n",
            "Run 6: 0.139 ms\n",
            "Run 7: 0.121 ms\n",
            "Run 8: 0.119 ms\n",
            "Run 9: 0.119 ms\n",
            "Run 10: 0.125 ms\n",
            "\n",
            "Average over 10 runs: 0.171 ms ± 0.063 ms.\n"
          ]
        }
      ]
    }
  ]
}